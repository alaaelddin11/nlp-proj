# -*- coding: utf-8 -*-
"""Untitled9.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xVzTNMrWZvDJEIlk7uveUn5Au8xuEaTI
"""

import os
import json

# Upload kaggle.json manually first (via the file upload dialog in Colab)
from google.colab import files
files.upload()

# Move it to the correct location
!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

#!/bin/bash
! kaggle datasets download pes12017000148/food-ingredients-and-recipe-dataset-with-images

! unzip food-ingredients-and-recipe-dataset-with-images.zip

# ‚úÖ Final Full Script with Complete Ingredient Cleaning List

import torch
import torch.nn as nn
import torchvision.transforms as transforms
from torch.utils.data import Dataset, DataLoader
import pandas as pd
from PIL import Image
import os
import numpy as np
import ast
import re
from collections import Counter
from sklearn.metrics import average_precision_score
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MultiLabelBinarizer
from torchvision.models import efficientnet_b0, EfficientNet_B0_Weights

import nltk
nltk.download('stopwords')
nltk.download('wordnet')
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer

stop_words = set(stopwords.words('english'))
lemmatizer = WordNetLemmatizer()

unnecessary_words = [
    'cup', 'tsp', 'tbsp', 'ounce', 'oz', 'elbow', 'extravirgin', 'kosher', 'lb', 'gram', 'g', 'ml', 'slice',
    'chopped', 'diced', 'minced', 'large', 'small', 'medium', 'extra', 'fresh', 'unsalted', 'ground', 'finely',
    'coarsely', 'divided', 'plus', 'more', 'or', 'and', 'cups', 'juice', 'teaspoon', 'teaspoons', 'tablespoon',
    'tablespoons', 'pint', 'pints', 'quart', 'quarts', 'pound', 'pounds', 'dash', 'dashes', 'drop', 'drops',
    'package', 'packages', 'pan', 'tray', 'sheet', 'sheets', 'bottle', 'bottled', 'bag', 'grinder', 'mill',
    'mortar', 'pestle', 'springform', 'surface', 'kitchen', 'brush', 'equipment', 'thermometer', 'slicer',
    'spoon', 'shell', 'frozen', 'chilled', 'boiling', 'boilinghot', 'soft', 'softened', 'raw', 'hot', 'cold',
    'tender', 'firm', 'thin', 'thick', 'creamy', 'sweetened', 'unsweetened', 'dry', 'dried', 'grated',
    'shredded', 'slivered', 'blanched', 'toasted', 'roasted', 'baked', 'instant', 'split', 'reducedsodium',
    'lowsodium', 'lowsalt', 'coarse', 'fine', 'superfine', 'unpeeled', 'peeled', 'seeded', 'seedless',
    'packed', 'smashed', 'crushed', 'torn', 'broken', 'halved', 'quartered', 'beaten', 'sprinkled',
    'greasing', 'dusting', 'brushing', 'drizzling', 'melted', 'wellseasoned', 'wellshaken', 'whole',
    'very', 'all', 'allpurpose', 'natural', 'some', 'about', 'needed', 'such', 'additional', 'prepared', 'na',
    'as', 'on', 'in', 'with', 'to', 'from', 'for', 'into', 'of', 'by', 'at', 'an', 'a', 'other', 'loose',
    'loosely', 'minutes', 'maker', 'specialty', 'freerange', 'stores', 'supermarkets', 'foods', 'club',
    'wheel', 'sticks', 'twists', 'wedges', 'cubes', 'ring', 'rings', 'twist', 'tabasco',
    'maraschino', 'maldon', 'matzo', 'linguine', 'arborio', 'orzo', 'basmati', 'monterey', 'romano',
    'fontina', 'gruyere', 'california', 'english', 'turkish', 'greekstyle', 'greek', 'italian', 'spanish',
    'french', 'asian', 'chinese', 'persian', 'blanco', 'grand', 'marnier', 'espresso', 'cognac', 'vodka',
    'rum', 'brandy', 'champagne'
]

normalization_map = {
    'tomato paste': 'tomato', 'cherry tomatoes': 'tomato', 'tomato sauce': 'tomato',
    'garlic cloves': 'garlic', 'clove garlic': 'garlic', 'onions': 'onion', 'green onions': 'onion',
    'spring onions': 'onion', 'bell pepper': 'pepper', 'red pepper': 'pepper', 'black pepper': 'pepper',
    'egg yolk': 'egg', 'egg white': 'egg', 'yolk': 'egg', 'whites': 'egg'
}

unnecessary_pattern = re.compile(r'\b(?:' + '|'.join(unnecessary_words) + r')\b', flags=re.IGNORECASE)

def fix_encoding(text):
    replacements = {'√Ç¬Ω': '1/2', '√Ç¬º': '1/4', '√Ç¬æ': '3/4', '√¢‚Ç¨‚Äú': '-', '√¢‚Ç¨≈ì': '"', '√¢‚Ç¨': '"', '√¢‚Ç¨‚Ñ¢': "'", '√Ç': ''}
    for bad, good in replacements.items():
        text = text.replace(bad, good)
    return text

def clean_ingredient_list(raw_list):
    try:
        ingredients = ast.literal_eval(raw_list)
        cleaned = set()
        for ing in ingredients:
            ing = fix_encoding(ing.lower())
            ing = re.sub(r'\([^)]*\)', '', ing)
            ing = re.sub(r'[^a-z\s]', '', ing)
            ing = unnecessary_pattern.sub('', ing)
            words = ing.split()
            words = [lemmatizer.lemmatize(w) for w in words if w not in stop_words]
            ing = ' '.join(words).strip()
            ing = normalization_map.get(ing, ing)
            if len(ing) >= 3:
                cleaned.add(ing)
        return list(cleaned)
    except:
        return []


# Load and clean the data
csv_path = "/content/Food Ingredients and Recipe Dataset with Image Name Mapping.csv"
df = pd.read_csv(csv_path)
df = df[df['Cleaned_Ingredients'].notnull()]
df['Cleaned_Ingredients_List'] = df['Cleaned_Ingredients'].apply(clean_ingredient_list)

# Select top 50 ingredients
all_ingredients = [item for sub in df['Cleaned_Ingredients_List'] for item in sub]
top_50 = [item for item, _ in Counter(all_ingredients).most_common(50)]

def create_vector(ingredients, top_50):
    return [1 if ing in ingredients else 0 for ing in top_50]

df['Label_Vector'] = df['Cleaned_Ingredients_List'].apply(lambda x: create_vector(x, top_50))

# Step 3: Split and Save
from sklearn.model_selection import train_test_split
train_df, val_df = train_test_split(df, test_size=0.1, random_state=42)
train_df.to_csv("/content/train.csv", index=False)
val_df.to_csv("/content/val.csv", index=False)




class IngredientDataset(Dataset):
    def __init__(self, csv_file, img_dir, transform=None):
        self.data = pd.read_csv(csv_file)
        self.img_dir = img_dir
        self.transform = transform
        self.valid_data = []
        available = set(os.listdir(img_dir))
        for i in range(len(self.data)):
            name = self.data.iloc[i]['Image_Name']
            label = self.data.iloc[i]['Label_Vector']
            for ext in ['.jpg', '.jpeg', '.png']:
                if name + ext in available:
                    self.valid_data.append((name + ext, label))
                    break

    def __len__(self):
        return len(self.valid_data)

    def __getitem__(self, idx):
        fname, label = self.valid_data[idx]
        img = Image.open(os.path.join(self.img_dir, fname)).convert('RGB')
        if self.transform:
            img = self.transform(img)
        return img, torch.tensor(eval(label), dtype=torch.float32)


class FastIngredientClassifier(nn.Module):
    def __init__(self, num_classes):
        super().__init__()
        base = efficientnet_b0(weights=EfficientNet_B0_Weights.DEFAULT)
        for param in base.features.parameters():
            param.requires_grad = False
        self.backbone = nn.Sequential(*list(base.children())[:-1])
        self.classifier = nn.Sequential(
            nn.Flatten(),
            nn.Linear(1280, 512),
            nn.ReLU(),
            nn.Dropout(0.4),
            nn.Linear(512, num_classes)
        )

    def forward(self, x):
        x = self.backbone(x)
        return self.classifier(x)


def train_one_epoch(model, loader, optimizer, criterion, device):
    model.train()
    total_loss = 0
    for x, y in loader:
        x, y = x.to(device), y.to(device)
        optimizer.zero_grad()
        loss = criterion(model(x), y)
        loss.backward()
        optimizer.step()
        total_loss += loss.item()
    return total_loss / len(loader)

def evaluate(model, loader, device):
    model.eval()
    preds, trues = [], []
    with torch.no_grad():
        for x, y in loader:
            x = x.to(device)
            preds.append(torch.sigmoid(model(x)).cpu().numpy())
            trues.append(y.numpy())
    return average_precision_score(np.vstack(trues), np.vstack(preds), average='macro')



transform = transforms.Compose([
    transforms.Resize((300, 300)),
    transforms.RandomHorizontalFlip(),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])

train_loader = DataLoader(IngredientDataset("/content/train.csv", "/content/Food Images/Food Images", transform), batch_size=32, shuffle=True)
val_loader = DataLoader(IngredientDataset("/content/val.csv", "/content/Food Images/Food Images", transform), batch_size=32, shuffle=False)

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = FastIngredientClassifier(num_classes=50).to(device)
criterion = nn.BCEWithLogitsLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)

best_val = 0
patience = 3
no_improve = 0

for epoch in range(20):
    loss = train_one_epoch(model, train_loader, optimizer, criterion, device)
    val_map = evaluate(model, val_loader, device)
    print(f"üìä Epoch {epoch+1} | Loss: {loss:.4f} | Val mAP: {val_map:.4f}")
    if val_map > best_val:
        best_val = val_map
        no_improve = 0
        torch.save(model.state_dict(), "best_model.pt")
        print(f"‚úÖ Best model saved with Val mAP: {val_map:.4f}")
    else:
        no_improve += 1
    if no_improve >= patience:
        print("‚èπÔ∏è Early stopping: no improvement in val mAP")
        break

# ‚úÖ Final Full Script with Complete Ingredient Cleaning List

import torch
import torch.nn as nn
import torchvision.transforms as transforms
from torch.utils.data import Dataset, DataLoader
import pandas as pd
from PIL import Image
import os
import numpy as np
import ast
import re
from collections import Counter
from sklearn.metrics import f1_score, precision_score, recall_score
from sklearn.metrics import average_precision_score
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MultiLabelBinarizer
from torchvision.models import efficientnet_b0, EfficientNet_B0_Weights

import nltk
nltk.download('stopwords')
nltk.download('wordnet')
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer

stop_words = set(stopwords.words('english'))
lemmatizer = WordNetLemmatizer()

unnecessary_words = [
    'cup', 'tsp', 'tbsp', 'ounce', 'oz', 'elbow', 'extravirgin', 'kosher', 'lb', 'gram', 'g', 'ml', 'slice',
    'chopped', 'diced', 'minced', 'large', 'small', 'medium', 'extra', 'fresh', 'unsalted', 'ground', 'finely',
    'coarsely', 'divided', 'plus', 'more', 'or', 'and', 'cups', 'juice', 'teaspoon', 'teaspoons', 'tablespoon',
    'tablespoons', 'pint', 'pints', 'quart', 'quarts', 'pound', 'pounds', 'dash', 'dashes', 'drop', 'drops',
    'package', 'packages', 'pan', 'tray', 'sheet', 'sheets', 'bottle', 'bottled', 'bag', 'grinder', 'mill',
    'mortar', 'pestle', 'springform', 'surface', 'kitchen', 'brush', 'equipment', 'thermometer', 'slicer',
    'spoon', 'shell', 'frozen', 'chilled', 'boiling', 'boilinghot', 'soft', 'softened', 'raw', 'hot', 'cold',
    'tender', 'firm', 'thin', 'thick', 'creamy', 'sweetened', 'unsweetened', 'dry', 'dried', 'grated',
    'shredded', 'slivered', 'blanched', 'toasted', 'roasted', 'baked', 'instant', 'split', 'reducedsodium',
    'lowsodium', 'lowsalt', 'coarse', 'fine', 'superfine', 'unpeeled', 'peeled', 'seeded', 'seedless',
    'packed', 'smashed', 'crushed', 'torn', 'broken', 'halved', 'quartered', 'beaten', 'sprinkled',
    'greasing', 'dusting', 'brushing', 'drizzling', 'melted', 'wellseasoned', 'wellshaken', 'whole',
    'very', 'all', 'allpurpose', 'natural', 'some', 'about', 'needed', 'such', 'additional', 'prepared', 'na',
    'as', 'on', 'in', 'with', 'to', 'from', 'for', 'into', 'of', 'by', 'at', 'an', 'a', 'other', 'loose',
    'loosely', 'minutes', 'maker', 'specialty', 'freerange', 'stores', 'supermarkets', 'foods', 'club',
    'wheel', 'sticks', 'twists', 'wedges', 'cubes', 'ring', 'rings', 'twist', 'tabasco',
    'maraschino', 'maldon', 'matzo', 'linguine', 'arborio', 'orzo', 'basmati', 'monterey', 'romano',
    'fontina', 'gruyere', 'california', 'english', 'turkish', 'greekstyle', 'greek', 'italian', 'spanish',
    'french', 'asian', 'chinese', 'persian', 'blanco', 'grand', 'marnier', 'espresso', 'cognac', 'vodka',
    'rum', 'brandy', 'champagne'
]

normalization_map = {
    # Tomato variants
    'tomato paste': 'tomato', 'cherry tomatoes': 'tomato', 'tomato sauce': 'tomato',
    'sun dried tomatoes': 'tomato', 'roma tomatoes': 'tomato',

    # Garlic
    'garlic cloves': 'garlic', 'clove garlic': 'garlic', 'minced garlic': 'garlic', 'garlic clove': 'garlic',

    # Onion variants
    'onions': 'onion', 'green onions': 'onion', 'spring onions': 'onion', 'yellow onion': 'onion', 'red onion': 'onion',

    # Pepper variants
    'bell pepper': 'pepper', 'red pepper': 'pepper', 'green pepper': 'pepper', 'black pepper': 'pepper', 'freshly black pepper': 'pepper',

    # Egg variants
    'egg yolk': 'egg', 'egg white': 'egg', 'yolk': 'egg', 'whites': 'egg', 'eggs': 'egg',

    # Oil types
    'extra virgin olive oil': 'olive oil', 'vegetable oil': 'oil', 'canola oil': 'oil', 'olive oil': 'oil',

    # Dairy
    'whole milk': 'milk', 'low fat milk': 'milk', 'buttermilk': 'milk', 'cheddar cheese': 'cheese',
    'mozzarella cheese': 'cheese', 'parmesan cheese': 'cheese',

    # Herbs
    'cilantro leaves': 'cilantro', 'fresh cilantro': 'cilantro', 'parsley leaves': 'parsley',
    'fresh parsley': 'parsley',

    # Sugars
    'brown sugar': 'sugar', 'white sugar': 'sugar', 'granulated sugar': 'sugar',

    # Flour
    'all purpose flour': 'flour', 'whole wheat flour': 'flour', 'wheat flour': 'flour',

    # Butter
    'unsalted butter': 'butter', 'salted butter': 'butter',

    # Misc
    'baking soda': 'baking soda', 'baking powder': 'baking powder', 'chili flakes': 'chili',
    'crushed red pepper': 'chili', 'scallions': 'onion', 'garam masala': 'spice', 'cumin seeds': 'cumin'
}


unnecessary_pattern = re.compile(r'\b(?:' + '|'.join(unnecessary_words) + r')\b', flags=re.IGNORECASE)

def fix_encoding(text):
    replacements = {'√Ç¬Ω': '1/2', '√Ç¬º': '1/4', '√Ç¬æ': '3/4', '√¢‚Ç¨‚Äú': '-', '√¢‚Ç¨≈ì': '"', '√¢‚Ç¨': '"', '√¢‚Ç¨‚Ñ¢': "'", '√Ç': ''}
    for bad, good in replacements.items():
        text = text.replace(bad, good)
    return text

def clean_ingredient_list(raw_list):
    try:
        ingredients = ast.literal_eval(raw_list)
        cleaned = set()
        for ing in ingredients:
            ing = fix_encoding(ing.lower())
            ing = re.sub(r'\([^)]*\)', '', ing)
            ing = re.sub(r'[^a-z\s]', '', ing)
            ing = unnecessary_pattern.sub('', ing)
            words = ing.split()
            words = [lemmatizer.lemmatize(w) for w in words if w not in stop_words]
            ing = ' '.join(words).strip()
            ing = normalization_map.get(ing, ing)
            if len(ing) >= 3:
                cleaned.add(ing)
        return list(cleaned)
    except:
        return []


# Load and clean the data
csv_path = "/content/Food Ingredients and Recipe Dataset with Image Name Mapping.csv"
df = pd.read_csv(csv_path)
df = df[df['Cleaned_Ingredients'].notnull()]
df['Cleaned_Ingredients_List'] = df['Cleaned_Ingredients'].apply(clean_ingredient_list)

# Select top 50 ingredients
all_ingredients = [item for sub in df['Cleaned_Ingredients_List'] for item in sub]
top_50 = [item for item, _ in Counter(all_ingredients).most_common(50)]

def create_vector(ingredients, top_50):
    return [1 if ing in ingredients else 0 for ing in top_50]

df['Label_Vector'] = df['Cleaned_Ingredients_List'].apply(lambda x: create_vector(x, top_50))

# Step 3: Split and Save
from sklearn.model_selection import train_test_split
train_df, val_df = train_test_split(df, test_size=0.1, random_state=42)
train_df.to_csv("/content/train.csv", index=False)
val_df.to_csv("/content/val.csv", index=False)




class IngredientDataset(Dataset):
    def __init__(self, csv_file, img_dir, transform=None):
        self.data = pd.read_csv(csv_file)
        self.img_dir = img_dir
        self.transform = transform
        self.valid_data = []
        available = set(os.listdir(img_dir))
        for i in range(len(self.data)):
            name = self.data.iloc[i]['Image_Name']
            label = self.data.iloc[i]['Label_Vector']
            for ext in ['.jpg', '.jpeg', '.png']:
                if name + ext in available:
                    self.valid_data.append((name + ext, label))
                    break

    def __len__(self):
        return len(self.valid_data)

    def __getitem__(self, idx):
        fname, label = self.valid_data[idx]
        img = Image.open(os.path.join(self.img_dir, fname)).convert('RGB')
        if self.transform:
            img = self.transform(img)
        return img, torch.tensor(eval(label), dtype=torch.float32)


class FastIngredientClassifier(nn.Module):
    def __init__(self, num_classes):
        super().__init__()
        base = efficientnet_b0(weights=EfficientNet_B0_Weights.DEFAULT)

        # ‚úÖ Unfreeze all layers
        for param in base.features.parameters():
            param.requires_grad = True

        self.backbone = nn.Sequential(*list(base.children())[:-1])
        self.classifier = nn.Sequential(
            nn.Flatten(),
            nn.Linear(1280, 512),
            nn.ReLU(),
            nn.Dropout(0.4),
            nn.Linear(512, num_classes)
        )

    def forward(self, x):
        x = self.backbone(x)
        return self.classifier(x)

# ‚úÖ Recalculate pos_weight for imbalanced classes
# ‚úÖ Setup
device = torch.device("cuda" if torch.cuda.is_available() else "cpu") # Define device first
label_matrix = np.array(df['Label_Vector'].tolist())
ingredient_counts = np.sum(label_matrix, axis=0)
pos_weight = torch.tensor((len(df) - ingredient_counts) / ingredient_counts, dtype=torch.float32).to(device)


model = FastIngredientClassifier(num_classes=50).to(device)
criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)
optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)
scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=2)

# ‚úÖ Updated evaluation with threshold tuning + F1
def evaluate(model, loader, device, threshold=0.3):
    model.eval()
    preds, trues = [], []
    with torch.no_grad():
        for x, y in loader:
            x = x.to(device)
            output = torch.sigmoid(model(x)).cpu().numpy()
            preds.append(output)
            trues.append(y.numpy())

    preds = np.vstack(preds)
    trues = np.vstack(trues)
    bin_preds = (preds > threshold).astype(int)

    f1 = f1_score(trues, bin_preds, average='macro', zero_division=0)
    recall = recall_score(trues, bin_preds, average='macro', zero_division=0)
    precision = precision_score(trues, bin_preds, average='macro', zero_division=0)
    map_score = average_precision_score(trues, preds, average='macro')
    return map_score, f1, recall, precision

# Define the transform here, before the DataLoader
transform = transforms.Compose([
    transforms.Resize((300, 300)),
    transforms.RandomHorizontalFlip(),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])

# Define the DataLoaders here
train_loader = DataLoader(IngredientDataset("/content/train.csv", "/content/Food Images/Food Images", transform), batch_size=32, shuffle=True)
val_loader = DataLoader(IngredientDataset("/content/val.csv", "/content/Food Images/Food Images", transform), batch_size=32, shuffle=False)


# ‚úÖ Train loop
best_val = 0
patience = 5
no_improve = 0

for epoch in range(30):
    model.train()
    total_loss = 0
    for x, y in train_loader:
        x, y = x.to(device), y.to(device)
        optimizer.zero_grad()
        loss = criterion(model(x), y)
        loss.backward()
        optimizer.step()
        total_loss += loss.item()

    avg_loss = total_loss / len(train_loader)
    val_map, val_f1, val_recall, val_precision = evaluate(model, val_loader, device)

    print(f"üìä Epoch {epoch+1} | Loss: {avg_loss:.4f} | Val mAP: {val_map:.4f} | F1: {val_f1:.4f} | Recall: {val_recall:.4f} | Precision: {val_precision:.4f}")

    if val_map > best_val:
        best_val = val_map
        no_improve = 0
        torch.save(model.state_dict(), "best_model.pt")
        print(f"‚úÖ Best model saved with Val mAP: {val_map:.4f}")
    else:
        no_improve += 1

    scheduler.step(val_map)

    if no_improve >= patience:
        print("‚èπÔ∏è Early stopping: no improvement in val mAP")
        break

def compute_subset_accuracy(model, loader, device):
    model.eval()
    correct = 0
    total = 0
    with torch.no_grad():
        for x, y in loader:
            x = x.to(device)
            outputs = torch.sigmoid(model(x)).cpu().numpy()
            preds = (outputs > 0.5).astype(int)
            true = y.numpy().astype(int)
            correct += np.all(preds == true, axis=1).sum()
            total += y.size(0)
    return correct / total

from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score

def compute_f1_precision_recall(model, loader, device):
    model.eval()
    preds, trues = [], []
    with torch.no_grad():
        for x, y in loader:
            x = x.to(device)
            y = y.numpy()
            outputs = torch.sigmoid(model(x)).cpu().numpy()
            preds.append((outputs > 0.2).astype(int))
            trues.append(y)
    preds = np.vstack(preds)
    trues = np.vstack(trues)
    f1 = f1_score(trues, preds, average='samples')
    acc = accuracy_score(trues, preds)
    prec = precision_score(trues, preds, average='samples', zero_division=0)
    rec = recall_score(trues, preds, average='samples')
    return acc, f1, prec, rec

acc, f1, prec, rec = compute_f1_precision_recall(model, val_loader, device='cuda')
print(f" F1: {f1:.4f} | Precision: {prec:.4f} | Recall: {rec:.4f}")

# Must match the one used during training
top_50 = [item for item, _ in Counter(all_ingredients).most_common(50)]

def smart_predictions(outputs, threshold=0.4, fallback_topk=3):
    preds = np.zeros_like(outputs)
    for i in range(outputs.shape[0]):
        confident_indices = np.where(outputs[i] > threshold)[0]

        if len(confident_indices) > 0:
            preds[i, confident_indices] = 1
        else:
            top_indices = np.argsort(outputs[i])[-fallback_topk:]
            preds[i, top_indices] = 1
    return preds.astype(int)

def decode_predictions(model, loader, device, ingredient_list, threshold=0.3, fallback_topk=3, num_samples=10):
    model.eval()
    results = []
    with torch.no_grad():
        for i, (images, labels) in enumerate(loader):
            if i >= num_samples:
                break
            images = images.to(device)
            outputs = torch.sigmoid(model(images)).cpu().numpy()
            preds = smart_predictions(outputs, threshold=threshold, fallback_topk=fallback_topk)
            true_labels = labels.numpy()

            for pred_vec, true_vec in zip(preds, true_labels):
                predicted_ings = [ingredient_list[j] for j in range(len(pred_vec)) if pred_vec[j] == 1]
                actual_ings = [ingredient_list[j] for j in range(len(true_vec)) if true_vec[j] == 1]
                results.append((predicted_ings, actual_ings))
    return results

# üß™ Run it
results = decode_predictions(model, val_loader, device='cuda', ingredient_list=top_50, threshold=0.3, fallback_topk=3, num_samples=30)

# üìã Show results
for i, (pred, true) in enumerate(results):
    print(f"\nüîç Sample {i+1}")
    print(f"‚úÖ Actual:    {true}")
    print(f"ü§ñ Predicted: {pred}")

import os
import pandas as pd
from torchvision import transforms
from PIL import Image
import torch
from torch.utils.data import Dataset
import numpy as np
import matplotlib.pyplot as plt

# üßº Step 1: Load CSV and fix missing .jpg if needed
val_df = pd.read_csv("/content/val.csv")

# Make sure label vectors are parsed correctly
val_df['Label_Vector'] = val_df['Label_Vector'].apply(lambda x: list(map(int, x.strip('[]').split(','))))

# Add .jpg if missing in Image_Name column
val_df['Image_Name'] = val_df['Image_Name'].apply(lambda x: x if x.endswith('.jpg') else x + '.jpg')

# üß± Step 2: Transform
transform = transforms.Compose([
    transforms.Resize((128, 128)),
    transforms.ToTensor()
])

# ‚úÖ Step 3: Dataset definition
class IngredientDataset(Dataset):
    def __init__(self, df, img_dir, transform=None):
        self.df = df.reset_index(drop=True)
        self.img_dir = img_dir
        self.transform = transform
        self.labels = df['Label_Vector'].apply(np.array).tolist()

    def __len__(self):
        return len(self.df)

    def __getitem__(self, idx):
        row = self.df.iloc[idx]
        img_path = os.path.join(self.img_dir, row['Image_Name'])
        if not os.path.exists(img_path):
            raise FileNotFoundError(f"‚ùå Image not found at: {img_path}")
        image = Image.open(img_path).convert("RGB")
        if self.transform:
            image = self.transform(image)
        label = torch.tensor(self.labels[idx], dtype=torch.float32)
        return image, label

# üß† Step 4: Create dataset
val_dataset = IngredientDataset(val_df, img_dir="/content/Food Images/Food Images", transform=transform)

# üëÅÔ∏è Step 5: Show image + predictions
def smart_predictions(outputs, threshold=0.3, fallback_topk=3):
    preds = np.zeros_like(outputs)
    for i in range(outputs.shape[0]):
        confident_indices = np.where(outputs[i] > threshold)[0]
        if len(confident_indices) > 0:
            preds[i, confident_indices] = 1
        else:
            top_indices = np.argsort(outputs[i])[-fallback_topk:]
            preds[i, top_indices] = 1
    return preds.astype(int)

def show_image_predictions(model, dataset, ingredient_list, device, threshold=0.3, fallback_topk=5, num_samples=5):
    model.eval()
    fig, axs = plt.subplots(num_samples, 1, figsize=(8, num_samples * 3))
    axs = axs if num_samples > 1 else [axs]

    with torch.no_grad():
        for idx in range(num_samples):
            image, label = dataset[idx]
            image_input = image.unsqueeze(0).to(device)
            output = torch.sigmoid(model(image_input)).cpu().numpy()[0]

            # Smart prediction logic
            confident_indices = np.where(output > threshold)[0]
            if len(confident_indices) == 0:
                top_indices = np.argsort(output)[-fallback_topk:]
                pred_indices = top_indices
            else:
                pred_indices = confident_indices

            predicted_ings = [ingredient_list[i] for i in pred_indices]
            actual_ings = [ingredient_list[i] for i in range(len(label)) if label[i] == 1]

            # Show image
            img_np = image.permute(1, 2, 0).numpy()
            axs[idx].imshow(img_np)
            axs[idx].axis("off")
            axs[idx].set_title(f"‚úÖ Actual: {actual_ings}\nü§ñ Predicted: {predicted_ings}", fontsize=10)

    plt.tight_layout()
    plt.show()

# üöÄ Run it
show_image_predictions(model, val_dataset, top_50, device='cuda', threshold=0.3, fallback_topk=5, num_samples=5)

train_losses = []
val_losses = []

num_epochs=20

for epoch in range(num_epochs):
    model.train()
    running_loss = 0.0

    for images, labels in train_loader:
        images = images.to(device)
        labels = labels.to(device).float()

        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        running_loss += loss.item()

    avg_train_loss = running_loss / len(train_loader)
    train_losses.append(avg_train_loss)

    # üìâ Validation loss
    model.eval()
    val_running_loss = 0.0
    with torch.no_grad():
        for images, labels in val_loader:
            images = images.to(device)
            labels = labels.to(device).float()
            outputs = model(images)
            loss = criterion(outputs, labels)
            val_running_loss += loss.item()

    avg_val_loss = val_running_loss / len(val_loader)
    val_losses.append(avg_val_loss)

    print(f"üìä Epoch {epoch+1} | Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f}")

import matplotlib.pyplot as plt

plt.figure(figsize=(8, 5))
plt.plot(train_losses, label='Training loss', color='blue')
plt.plot(val_losses, label='Validation loss', color='red')
plt.title('Training and validation loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()